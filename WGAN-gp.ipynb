{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WDCGAN-gp.ipynb","version":"0.3.2","provenance":[{"file_id":"125CR_GyiWkeb3NTB2H5SCZ9oYGwJ2tZ6","timestamp":1549822258026}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"h1TQ1bJU18aP","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","from torch.utils.data import (Dataset,DataLoader,TensorDataset)\n","from torchvision import models\n","from torch import nn,optim\n","import tqdm\n","from torchvision.datasets import FashionMNIST\n","from torchvision.datasets import MNIST\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uLGs5EoLet-j","colab_type":"text"},"cell_type":"markdown","source":["以下で学習データをダウンロード"]},{"metadata":{"id":"x3_CuAKQ1_pu","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0iILKGh22HSF","colab_type":"code","colab":{}},"cell_type":"code","source":["!tar xf 102flowers.tgz\n","!mkdir oxford=102\n","!mkdir oxford=102/jpg\n","!mv jpg/*.jpg oxford=102/jpg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BFOe7yN92LDs","colab_type":"code","colab":{}},"cell_type":"code","source":["img_data=ImageFolder(\"oxford=102/\",transform=transforms.Compose([transforms.Resize(80),transforms.CenterCrop(64),transforms.ToTensor()]))\n","batch_size=64\n","img_loader=DataLoader(img_data,batch_size=batch_size,shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c5rLtnQp5lJ9","colab_type":"text"},"cell_type":"markdown","source":["以下２セルは人の顔を用いる時"]},{"metadata":{"id":"Rj7xNv7t19wB","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n","!tar xf lfw-deepfunneled.tgz\n","!mkdir lfw-deepfunneled/train\n","!mkdir lfw-deepfunneled/test\n","!mv lfw-deepfunneled/[A-W]* lfw-deepfunneled/train\n","!mv lfw-deepfunneled/[X-Z]* lfw-deepfunneled/test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CeOSLArW2tGt","colab_type":"code","colab":{}},"cell_type":"code","source":["img_data=ImageFolder(\"lfw-deepfunneled/train\",transform=transforms.Compose([transforms.Resize(80),transforms.CenterCrop(64),transforms.ToTensor()]))\n","batch_size=64\n","img_loader=DataLoader(img_data,batch_size=batch_size,shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MslKvSDnpGpG","colab_type":"text"},"cell_type":"markdown","source":["以下1セルはMNIST"]},{"metadata":{"id":"SfRQcKSopNR8","colab_type":"code","colab":{}},"cell_type":"code","source":["img_data=MNIST(\"/MNIST\",train=True,download=True,transform=transforms.Compose([transforms.Resize(64),transforms.ToTensor()]))\n","batch_size=128\n","img_loader=DataLoader(img_data,batch_size=batch_size,shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6oxOHl9ufDtl","colab_type":"text"},"cell_type":"markdown","source":["以下でモデルを定義"]},{"metadata":{"id":"hjb3-4_M2NFo","colab_type":"code","colab":{}},"cell_type":"code","source":["nz=100\n","ngf=32\n","in_dim=1 #カラー画像なら3白黒画像なら1\n","\n","class GNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.main=nn.Sequential(\n","        nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n","        nn.ReLU(inplace=True),\n","        nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n","        nn.ReLU(inplace=True),\n","        nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n","        nn.ReLU(inplace=True),\n","        nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n","        nn.ReLU(inplace=True),\n","        nn.ConvTranspose2d(ngf, in_dim, 4, 2, 1, bias=False),\n","        nn.Tanh()\n","    )\n","  def forward(self,x):\n","    out=self.main(x)\n","    return out\n","    \n","ndf=32\n","\n","class DNet(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.main=nn.Sequential(\n","        nn.Conv2d(in_dim, ndf, 4, 2, 1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n","        nn.LeakyReLU(0.2, inplace=True),\n","        nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n","    )\n","    \n","  def forward(self,x):\n","    out=self.main(x)\n","    return out.squeeze()\n","        \n","d=DNet().to(\"cuda:0\")\n","g=GNet().to(\"cuda:0\")\n","\n","opt_d=optim.Adam(d.parameters(),lr=0.0001,betas=(0,0.9))\n","opt_g=optim.Adam(g.parameters(),lr=0.0001,betas=(0,0.9))\n","\n","ones=torch.ones(batch_size).to(\"cuda:0\")\n","zeros=torch.zeros(batch_size).to(\"cuda:0\")\n","loss_f=nn.BCEWithLogitsLoss()\n","\n","fixed_z=torch.randn(batch_size,nz,1,1).to(\"cuda:0\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DJF_gAjN2PB6","colab_type":"code","colab":{}},"cell_type":"code","source":["from statistics import mean\n","\n","def train_dcgan(g, d, opt_g, opt_d, loader):\n","  log_loss_g=[]\n","  log_loss_d=[]\n","  roop=0\n","  for real_img,_ in tqdm.tqdm(loader):\n","    batch_len=len(real_img)\n","    z=torch.randn(batch_len,nz,1,1).to(\"cuda:0\")\n","    fake_img=g(z)\n","    fake_img_tensor=fake_img.detach()\n","    \n","    \n","    real_img=real_img.to(\"cuda:0\")\n","    real_out=d(real_img)\n","    loss_d_real=torch.sum(real_out)\n","    fake_out=d(fake_img)\n","    loss_d_fake=torch.sum(fake_out)\n","    \n","    naibun_loss=torch.tensor(0.0).to(\"cuda:0\")\n","    naibun=torch.rand(1).to(\"cuda:0\")\n","    img_naibun = real_img*naibun + fake_img*(1-naibun)\n","    img_naibun = img_naibun.detach()\n","    img_naibun = torch.tensor(img_naibun,requires_grad=True)    \n","    fake_d=d(img_naibun)\n","    f = torch.autograd.grad(outputs=fake_d, inputs=img_naibun,\n","                              grad_outputs=torch.ones(fake_d.size()).to(\"cuda:0\"),\n","                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n","    f=f.view(f.size()[0],-1)\n","    naibun_loss = ((f.norm(2, dim=1) - 1) ** 2).sum()\n","\n","    lammda=10\n","    \n","    loss_d=-loss_d_real+loss_d_fake+lammda*naibun_loss\n","    log_loss_d.append(loss_d.item())\n","    d.zero_grad(),g.zero_grad()\n","    loss_d.backward()\n","    opt_d.step()\n","    \n","    z=torch.randn(batch_len,nz,1,1).to(\"cuda:0\")\n","    fake_img=g(z)\n","    out=d(fake_img)\n","    loss_g=-torch.sum(out)\n","    log_loss_g.append(loss_g.item())\n","    d.zero_grad(),g.zero_grad()\n","    loss_g.backward()\n","    opt_g.step()\n","    roop+=1\n","  print(mean(log_loss_g),mean(log_loss_d),naibun_loss)\n","  return mean(log_loss_g), mean(log_loss_d)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"51axUttDgbMQ","colab_type":"text"},"cell_type":"markdown","source":["以下のセルで学習"]},{"metadata":{"id":"2XrErjyo2SGJ","colab_type":"code","colab":{}},"cell_type":"code","source":["from IPython.display import Image,display_jpeg\n","from torchvision.utils import save_image\n","\n","for epoch in range(300): #range(エポック数)適宜変更可能\n","  print(epoch)\n","  train_dcgan(g,d,opt_g,opt_d,img_loader)\n","  if epoch%1==0:\n","    torch.save(\n","        g.state_dict(),\n","        \"g_{:03d}.prm\".format(epoch),\n","        pickle_protocol=4)\n","    torch.save(\n","        d.state_dict(),\n","        \"d_{:03d}.prm\".format(epoch),\n","        pickle_protocol=4)\n","    generated_img=g(fixed_z[:64,:,:,:])\n","    save_image(generated_img,\"{:03d}.jpg\".format(epoch))\n","    display_jpeg(Image(\"{:03d}.jpg\".format(epoch)))"],"execution_count":0,"outputs":[]}]}